{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Extract sheets from the excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: MVN-J-Boning-64-001.xlsx\n",
      "Processed and saved: MVN-J-Boning-64-002.xlsx\n",
      "Processed and saved: MVN-J-Boning-64-003.xlsx\n",
      "Processed and saved: MVN-J-Boning-64-004.xlsx\n",
      "Processed and saved: MVN-J-Boning-64-005.xlsx\n",
      "Processed and saved: MVN-J-Boning-64-006.xlsx\n",
      "Processed and saved: MVN-J-Boning-79-001.xlsx\n",
      "Processed and saved: MVN-J-Boning-90-001.xlsx\n",
      "Processed and saved: MVN-J-Boning-90-002.xlsx\n",
      "Processed and saved: MVN-J-Boning-90-003.xlsx\n",
      "Processed and saved: MVN-J-Boning-90-004.xlsx\n",
      "Processed and saved: MVN-J-Slicing-64-001.xlsx\n",
      "Processed and saved: MVN-J-Slicing-73-001.xlsx\n",
      "Processed and saved: MVN-J-Slicing-87-001.xlsx\n",
      "Processed and saved: MVN-S-Boning-63-001.xlsx\n",
      "Processed and saved: MVN-S-Boning-63-002.xlsx\n",
      "Processed and saved: MVN-S-Boning-63-003.xlsx\n",
      "Processed and saved: MVN-S-Boning-76-001.xlsx\n",
      "Processed and saved: MVN-S-Boning-76-002.xlsx\n",
      "Processed and saved: MVN-S-Boning-89-001.xlsx\n",
      "Processed and saved: MVN-S-Boning-89-002.xlsx\n",
      "Processed and saved: MVN-S-Boning-89-003.xlsx\n",
      "Processed and saved: MVN-S-Boning-89-004.xlsx\n",
      "Processed and saved: MVN-S-Slicing-63-001.xlsx\n",
      "Processed and saved: MVN-S-Slicing-73-001.xlsx\n",
      "Processed and saved: MVN-S-Slicing-87-001.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define input and output folders\n",
    "input_folder = \"data\"\n",
    "velocity_output_folder = \"extracted_data\\\\velocity\"\n",
    "acceleration_output_folder = \"extracted_data\\\\acceleration\"\n",
    "\n",
    "# Make sure output folders exist\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "os.makedirs(velocity_output_folder, exist_ok=True)\n",
    "os.makedirs(acceleration_output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each excel file\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "\n",
    "        # Read the 'Segment Velocity' and 'Segment Acceleration' sheets\n",
    "        velocity_df = xls.parse('Segment Velocity')\n",
    "        acceleration_df = xls.parse('Segment Acceleration')\n",
    "\n",
    "        # Create output paths\n",
    "        velocity_output_path = os.path.join(\n",
    "            velocity_output_folder, f\"{file_name.split('.')[0]}-Velocity.csv\")\n",
    "\n",
    "        acceleration_output_path = os.path.join(\n",
    "            acceleration_output_folder, f\"{file_name.split('.')[0]}-Acceleration.csv\")\n",
    "\n",
    "        # Save the extracted data to a new csv file\n",
    "        velocity_df.to_csv(velocity_output_path, index=False)\n",
    "        acceleration_df.to_csv(acceleration_output_path, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Merge velocity and acceleration datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Define folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output folders\n",
    "velocity_folder = \"extracted_data\\\\velocity\"\n",
    "acceleration_folder = \"extracted_data\\\\acceleration\"\n",
    "\n",
    "# Make sure output folders exist\n",
    "os.makedirs(velocity_folder, exist_ok=True)\n",
    "os.makedirs(velocity_folder, exist_ok=True)\n",
    "\n",
    "# Define folder for saving merged files\n",
    "merged_output_folder = 'acc_vel_merged_data'\n",
    "os.makedirs(merged_output_folder, exist_ok=True)  # Create the merged folder if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign labels based on the Marker sheet\n",
    "def assign_labels(frame_df, marker_df):\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through the marker dataframe\n",
    "    for index, row in marker_df.iterrows():\n",
    "        # Extract frame range and label number\n",
    "        frame_range = row['Frame']  # e.g., '0-195'\n",
    "        label = int(row['Label'].split()[0])  # Extract number from '3 - Reaching'\n",
    "        \n",
    "        # Split the frame range into start and end\n",
    "        start_frame, end_frame = map(int, frame_range.split('-'))\n",
    "        \n",
    "        # Assign label to each frame in the range\n",
    "        for frame in range(start_frame, end_frame + 1):\n",
    "            labels.append((frame, label))\n",
    "    \n",
    "    # Convert the list of frame-label pairs into a DataFrame\n",
    "    label_df = pd.DataFrame(labels, columns=['Frame', 'Label'])\n",
    "    \n",
    "    # Merge the labels with the original frame data\n",
    "    merged_df = pd.merge(frame_df, label_df, on='Frame', how='left')\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_files(velocity_file, acceleration_file, marker_file=None):\n",
    "    # Load the velocity and acceleration files\n",
    "    velocity_df = pd.read_csv(os.path.join(velocity_folder, velocity_file))\n",
    "    acceleration_df = pd.read_csv(os.path.join(acceleration_folder, acceleration_file))\n",
    "\n",
    "    # Handle boning-90-003: Copy Label from velocity to acceleration\n",
    "    if 'boning-90-003' in velocity_file.lower():\n",
    "        print(f\"Fixing missing Label in acceleration sheet for: {acceleration_file}\")\n",
    "        acceleration_df['Label'] = velocity_df['Label']\n",
    "\n",
    "    # Handle slicing-64-001: Rename Marker to Label\n",
    "    if 'slicing-64-001' in velocity_file.lower():\n",
    "        print(f\"Renaming 'Marker' to 'Label' for: {velocity_file} and {acceleration_file}\")\n",
    "        velocity_df.rename(columns={'Marker': 'Label'}, inplace=True)\n",
    "        acceleration_df.rename(columns={'Marker': 'Label'}, inplace=True)\n",
    "\n",
    "    # Handle slicing-87-001: Add Label from Marker sheet\n",
    "    if 'slicing-87-001' in velocity_file.lower():\n",
    "        if marker_file is not None:\n",
    "            print(f\"Adding Label from Marker sheet for: {velocity_file} and {acceleration_file}\")\n",
    "            marker_df = pd.read_csv(marker_file)\n",
    "            velocity_df = assign_labels(velocity_df, marker_df)\n",
    "            acceleration_df = assign_labels(acceleration_df, marker_df)\n",
    "\n",
    "    # Save the preprocessed data back to CSV files (overwrite or in new location)\n",
    "    velocity_df.to_csv(os.path.join(velocity_folder, velocity_file), index=False)\n",
    "    acceleration_df.to_csv(os.path.join(acceleration_folder, acceleration_file), index=False)\n",
    "\n",
    "    return velocity_file, acceleration_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing missing Label in acceleration sheet for: MVN-J-boning-90-003-Acceleration.csv\n",
      "Renaming 'Marker' to 'Label' for: MVN-J-slicing-64-001-Velocity.csv and MVN-J-slicing-64-001-Acceleration.csv\n",
      "Adding Label from Marker sheet for: MVN-J-slicing-87-001-Velocity.csv and MVN-J-slicing-87-001-Acceleration.csv\n"
     ]
    }
   ],
   "source": [
    "velocity_files_to_preprocess = [\n",
    "    'MVN-J-boning-90-003-Velocity.csv',\n",
    "    'MVN-J-slicing-64-001-Velocity.csv',\n",
    "    'MVN-J-slicing-87-001-Velocity.csv'\n",
    "]\n",
    "\n",
    "acceleration_files_to_preprocess = [\n",
    "    'MVN-J-boning-90-003-Acceleration.csv',\n",
    "    'MVN-J-slicing-64-001-Acceleration.csv',\n",
    "    'MVN-J-slicing-87-001-Acceleration.csv'\n",
    "]\n",
    "\n",
    "\n",
    "# Preprocess the files\n",
    "for velocity_file, acceleration_file in zip(velocity_files_to_preprocess, acceleration_files_to_preprocess):\n",
    "\n",
    "    marker_file = None\n",
    "    if 'slicing-87-001' in velocity_file.lower():\n",
    "        marker_file = 'data\\\\MVN-J-Slicing-87-001-Marker.csv'  # Adjust this path to the actual Marker file\n",
    "        \n",
    "    preprocess_files(velocity_file, acceleration_file, marker_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Function to merge acceleration and velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the velocity and acceleration data for each file\n",
    "def merge_acc_vel(velocity_file, acceleration_file):\n",
    "    # Read the velocity and acceleration data\n",
    "    velocity_df = pd.read_csv(os.path.join(velocity_folder, velocity_file))\n",
    "    acceleration_df = pd.read_csv(os.path.join(acceleration_folder, acceleration_file))\n",
    "\n",
    "    # Check if the common columns are present in both dataframes\n",
    "    common_cols = ['Frame', 'Label']\n",
    "    if not all(column in velocity_df.columns and column in acceleration_df.columns for column in common_cols):\n",
    "        print(f\"Error: Common columns not found in {velocity_file} and {acceleration_file}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # Merge the velocity and acceleration data on the common columns\n",
    "    merged_df = pd.merge(velocity_df, acceleration_df, on=common_cols, suffixes=('_Vel', '_Acc'))\n",
    "\n",
    "    # Save the merged dataframe as a new CSV file\n",
    "    merged_filename = velocity_file.replace('-Velocity', '-Merged')\n",
    "    merged_df.to_csv(os.path.join(merged_output_folder, merged_filename), index=False)\n",
    "\n",
    "    print(f\"Successfully merged and saved: {merged_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Perform merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged and saved: MVN-J-Boning-64-001-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-64-002-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-64-003-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-64-004-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-64-005-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-64-006-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-79-001-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-90-001-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-90-002-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-90-003-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Boning-90-004-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Slicing-64-001-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Slicing-73-001-Merged.csv\n",
      "Successfully merged and saved: MVN-J-Slicing-87-001-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-63-001-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-63-002-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-63-003-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-76-001-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-76-002-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-89-001-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-89-002-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-89-003-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Boning-89-004-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Slicing-63-001-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Slicing-73-001-Merged.csv\n",
      "Successfully merged and saved: MVN-S-Slicing-87-001-Merged.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all velocity and acceleration files\n",
    "velocity_files = [f for f in os.listdir(velocity_folder) if f.endswith(\".csv\")]\n",
    "acceleration_files = [f for f in os.listdir(acceleration_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "for velocity_file in velocity_files:\n",
    "    # Find the corresponding acceleration file by replacing \"Velocity\" with \"Acceleration\"\n",
    "    acceleration_file = velocity_file.replace(\"Velocity\", \"Acceleration\")\n",
    "    \n",
    "    if acceleration_file in acceleration_files:\n",
    "        merge_acc_vel(velocity_file, acceleration_file)\n",
    "    else:\n",
    "        print(f\"Corresponding acceleration file not found for {velocity_file}. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "[3 5 4 8 2 7]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('acc_vel_merged_data\\\\MVN-J-Slicing-87-001-Merged.csv')\n",
    "\n",
    "df.columns\n",
    "\n",
    "print (\"YES\" if 'Label' in df.columns else \"NO\")\n",
    "\n",
    "print (df['Label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Add knife category and shift column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: categorized_data\\MVN-J-Boning-64-001.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-64-002.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-64-003.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-64-004.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-64-005.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-64-006.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-79-001.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-90-001.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-90-002.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-90-003.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Boning-90-004.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Slicing-64-001.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Slicing-73-001.csv\n",
      "Processed and saved: categorized_data\\MVN-J-Slicing-87-001.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-63-001.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-63-002.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-63-003.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-76-001.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-76-002.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-89-001.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-89-002.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-89-003.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Boning-89-004.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Slicing-63-001.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Slicing-73-001.csv\n",
      "Processed and saved: categorized_data\\MVN-S-Slicing-87-001.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extracts the knife sharpness value from the filename and categorizes it.\n",
    ":param file_name: String, e.g., 'MVN-J-Boning-64-001_Acceleration.xlsx'\n",
    ":return: Categorical label ('Blunt', 'Medium', 'Sharp')\n",
    "\"\"\"\n",
    "# Categorize knife sharpness\n",
    "def add_sharpness_and_shift(file_name, df):\n",
    "    # Extract knife sharpness factor from filename (e.g., '64' in 'MVN-J-Boning-64-001')\n",
    "    knife_sharpness = int(file_name.split('-')[3])\n",
    "    \n",
    "    # Convert knife sharpness into categorical value\n",
    "    if knife_sharpness >= 85:\n",
    "        sharpness_category = 2  # Sharp\n",
    "    elif 70 <= knife_sharpness <= 84:\n",
    "        sharpness_category = 1  # Medium\n",
    "    else:\n",
    "        sharpness_category = 0  # Blunt\n",
    "    \n",
    "    # Add new column for sharpness category\n",
    "    df['Knife_Sharpness_Category'] = sharpness_category\n",
    "\n",
    "    # Extract the shift indicator from the filename (e.g., '001' in 'MVN-J-Boning-64-001')\n",
    "    shift_indicator = file_name.split('-')[4]  # '001', '002', etc.\n",
    "    \n",
    "    # Add new column for the shift indicator\n",
    "    df['Shift'] = shift_indicator\n",
    "    \n",
    "    return df\n",
    "\n",
    "input_folder = \"acc_vel_merged_data\"\n",
    "output_folder = \"categorized_data\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
    "\n",
    "for file_name in os.listdir(input_folder):  \n",
    "    if file_name.endswith(\".csv\"):\n",
    "\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Apply knife sharpness conversion function\n",
    "        df = add_sharpness_and_shift(file_name, df)\n",
    "\n",
    "        # Remove the \"merged\" annotation from the filename\n",
    "        new_file_name = file_name.replace(\"-Merged\", \"\")  # Replace \"Merged\" with an empty string\n",
    "\n",
    "        # Save the updated DataFrame to a new CSV file with the knife sharpness column\n",
    "        output_file_path = os.path.join(output_folder, new_file_name)\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Processed and saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "(54721, 141)\n"
     ]
    }
   ],
   "source": [
    "# Test the outcome\n",
    "df = pd.read_csv('categorized_data\\\\MVN-J-Slicing-87-001.csv')\n",
    "\n",
    "print(df['Knife_Sharpness_Category'].unique())\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Merge different shift datasets for each knife sharpness and person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge multiple CSV files for the same knife sharpness and activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge multiple CSV files for the same knife sharpness and activity\n",
    "def merge_files_for_activity_and_sharpness(file_list, output_file):\n",
    "    merged_df = pd.concat([pd.read_csv(file) for file in file_list], ignore_index=True)\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Merged file saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group the files by activity and knife sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the files by activity and knife sharpness\n",
    "def group_files_by_activity_and_sharpness(files):\n",
    "    grouped_files = {}\n",
    "    for file in files:\n",
    "        # Extract knife sharpness factor (64, 79, etc.) and activity (Boning, Slicing) from the filename\n",
    "        activity = file.split('-')[2]  # Extract activity (Boning, Slicing)\n",
    "        sharpness = file.split('-')[3]    # Extract the knife sharpness factor\n",
    "        \n",
    "        # Use both activity and sharpness as keys for grouping\n",
    "        key = f\"{activity}\"\n",
    "        if key not in grouped_files:\n",
    "            grouped_files[key] = []\n",
    "        grouped_files[key].append(file)\n",
    "    \n",
    "    return grouped_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function to process and merge files for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process and merge files for each person\n",
    "def process_and_merge_person_files(input_folder, output_folder, person_indicator):\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
    "    \n",
    "    # Filter files for the specified person (J or S)\n",
    "    person_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.startswith(f\"MVN-{person_indicator}\")]\n",
    "\n",
    "    # Group the files by activity and knife sharpness\n",
    "    grouped_files = group_files_by_activity_and_sharpness(person_files)\n",
    "\n",
    "    # Merge files for each group (e.g., Boning-64, Slicing-87)\n",
    "    for key, files in grouped_files.items():\n",
    "        output_filename = os.path.join(output_folder, f\"{person_indicator}_{key}.csv\")\n",
    "        merge_files_for_activity_and_sharpness(files, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved as workers\\J_Boning.csv\n",
      "Merged file saved as workers\\J_Slicing.csv\n",
      "Merged file saved as workers\\S_Boning.csv\n",
      "Merged file saved as workers\\S_Slicing.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage to merge files for Person 1 (J) and Person 2 (S)\n",
    "input_folder = \"categorized_data\"  # Folder containing all the raw CSV files\n",
    "output_folder_person1 = \"bone_slice\"  # Folder to save merged files for Person 1\n",
    "output_folder_person2 = \"bone_slice\"  # Folder to save merged files for Person 2\n",
    "\n",
    "# Merge files for Person 1 (J)\n",
    "process_and_merge_person_files(input_folder, output_folder_person1, \"J\")\n",
    "\n",
    "# Merge files for Person 2 (S)\n",
    "process_and_merge_person_files(input_folder, output_folder_person2, \"S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Adjusting the class labels to make them consistent for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels in the boning dataset have been updated.\n"
     ]
    }
   ],
   "source": [
    "# Load the boning dataset\n",
    "boning_df_P1 = pd.read_csv('bone_slice\\\\J_Boning.csv')\n",
    "boning_df_P2 = pd.read_csv('bone_slice\\\\S_Boning.csv')\n",
    "\n",
    "# Adjust the 'Dropping' class label from 5 to 8\n",
    "boning_df_P1['Label'] = boning_df_P1['Label'].replace({5: 8})\n",
    "boning_df_P2['Label'] = boning_df_P2['Label'].replace({5: 8})\n",
    "\n",
    "# Save the updated boning dataset\n",
    "boning_df_P1.to_csv('bone_slice\\\\J_Boning.csv', index=False)\n",
    "boning_df_P2.to_csv('bone_slice\\\\S_Boning.csv', index=False)\n",
    "\n",
    "print(\"Class labels in the boning dataset have been updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 2 3 8 1]\n",
      "[4 8 1 2 0 3]\n"
     ]
    }
   ],
   "source": [
    "# Check the class labels in the boning dataset\n",
    "print(boning_df_P1['Label'].unique())\n",
    "print(boning_df_P2['Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141397, 142)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boning_df_P1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Convert to 1-minute interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert 1-second data to 1-minute intervals\n",
    "def convert_to_one_minute_intervals(df):\n",
    "    # Create a 'Minute' column by dividing frames into groups of 60\n",
    "    if 'Minute' in df.columns:\n",
    "        df.drop(columns=['Minute'], inplace=True)\n",
    "\n",
    "    # Create a global frame counter based on the total number of rows\n",
    "    df['Global_Frame'] = df.index + 1  # Using the index as the frame number (starting from 1)\n",
    "    \n",
    "    # Create the 'Minute' column by dividing Global_Frame into groups of 60 seconds\n",
    "    df['Minute'] = df['Global_Frame'] // 60\n",
    "\n",
    "    # Define the columns for categorical data\n",
    "    categorical_columns = ['Label', 'Knife_Sharpness_Category', 'Shift']\n",
    "\n",
    "    # Define the columns for numerical data (excluding 'Frame')\n",
    "    numerical_columns = [col for col in df.columns if col not in categorical_columns and col not in ['Frame', 'Global_Frame', 'Minute']]\n",
    "\n",
    "    # Aggregation rules\n",
    "    aggregation = {}\n",
    "\n",
    "    # Set aggregation rules for categorical columns to take the mode (most frequent value)\n",
    "    for col in categorical_columns:\n",
    "        aggregation[col] = lambda x: x.mode()[0] if not x.mode().empty else x.iloc[0]  # Handle empty mode case\n",
    "\n",
    "    # Set aggregation rules for numerical columns to take the mean\n",
    "    for col in numerical_columns:\n",
    "        aggregation[col] = 'mean'\n",
    "    \n",
    "    # Group by the 'Minute' column and apply the aggregation rules\n",
    "    aggregated_df = df.groupby('Minute').agg(aggregation)\n",
    "\n",
    "    # Reset the index of the aggregated DataFrame\n",
    "    # aggregated_df.reset_index(inplace=True)\n",
    "\n",
    "    if 'Frame' in df.columns:\n",
    "        df.drop(columns=['Frame'], inplace=True)\n",
    "\n",
    "     # Drop the 'Global_Frame' column after conversion\n",
    "    if 'Global_Frame' in aggregated_df.columns:\n",
    "        aggregated_df.drop(columns=['Global_Frame'], inplace=True)\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141397, 142)\n",
      "(137732, 142)\n",
      "(125527, 142)\n",
      "(125637, 142)\n",
      "(2357, 141)\n",
      "(2296, 141)\n",
      "(2093, 141)\n",
      "(2094, 141)\n",
      "Conversion to 1-minute intervals completed.\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (assuming it's already been merged and processed)\n",
    "boning_P1 = pd.read_csv('bone_slice\\\\J_Boning.csv')\n",
    "boning_P2 = pd.read_csv('bone_slice\\\\S_Boning.csv')\n",
    "slicing_P1 = pd.read_csv('bone_slice\\\\J_Slicing.csv')\n",
    "slicing_P2 = pd.read_csv('bone_slice\\\\S_Slicing.csv')\n",
    "\n",
    "print(boning_P1.shape)\n",
    "print(boning_P2.shape)\n",
    "print(slicing_P1.shape)\n",
    "print(slicing_P2.shape)\n",
    "\n",
    "# Convert the dataset to 1-minute intervals\n",
    "boning_p1_min = convert_to_one_minute_intervals(boning_P1)\n",
    "boning_p2_min = convert_to_one_minute_intervals(boning_P2)\n",
    "slicing_p1_min = convert_to_one_minute_intervals(slicing_P1)\n",
    "slicing_p2_min = convert_to_one_minute_intervals(slicing_P2)\n",
    "\n",
    "print(boning_p1_min.shape)\n",
    "print(boning_p2_min.shape)\n",
    "print(slicing_p1_min.shape)\n",
    "print(slicing_p2_min.shape)\n",
    "\n",
    "# Save the 1 minute interval datasets\n",
    "boning_p1_min.to_csv('bone_slice_min\\\\J_Boning_min.csv')\n",
    "boning_p2_min.to_csv('bone_slice_min\\\\S_Boning_min.csv')\n",
    "slicing_p1_min.to_csv('bone_slice_min\\\\J_Slicing_min.csv')\n",
    "slicing_p2_min.to_csv('bone_slice_min\\\\S_Slicing_min.csv')\n",
    "\n",
    "print(\"Conversion to 1-minute intervals completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         Label  Knife_Sharpness_Category  Shift  Pelvis x_Vel  Pelvis y_Vel  \\\n",
      "Minute                                                                       \n",
      "0           4                         0      1           0.0           0.0   \n",
      "1           4                         0      1           0.0           0.0   \n",
      "2           4                         0      1           0.0           0.0   \n",
      "3           0                         0      1           0.0           0.0   \n",
      "4           0                         0      1           0.0           0.0   \n",
      "...       ...                       ...    ...           ...           ...   \n",
      "2352        4                         2      4           0.0           0.0   \n",
      "2353        4                         2      4           0.0           0.0   \n",
      "2354        4                         2      4           0.0           0.0   \n",
      "2355        8                         2      4           0.0           0.0   \n",
      "2356        8                         2      4           0.0           0.0   \n",
      "\n",
      "        Pelvis z_Vel  L5 x_Vel  L5 y_Vel  L5 z_Vel  L3 x_Vel  ...  \\\n",
      "Minute                                                        ...   \n",
      "0                0.0  0.027806 -0.051742  0.198527  0.022352  ...   \n",
      "1                0.0  0.043772 -0.035047  0.252839  0.052638  ...   \n",
      "2                0.0 -0.019464  0.056012  0.228783 -0.017915  ...   \n",
      "3                0.0 -0.136964  0.101034  0.211410 -0.138453  ...   \n",
      "4                0.0 -0.040060 -0.060612  0.178886 -0.038808  ...   \n",
      "...              ...       ...       ...       ...       ...  ...   \n",
      "2352             0.0 -0.082681  0.061437 -2.841879 -0.087390  ...   \n",
      "2353             0.0 -0.091301  0.055627 -2.847566 -0.086077  ...   \n",
      "2354             0.0 -0.063303  0.116892 -2.867200 -0.051457  ...   \n",
      "2355             0.0 -0.147414 -0.117135 -2.893580 -0.120714  ...   \n",
      "2356             0.0  0.205916  0.162724 -2.907978  0.198998  ...   \n",
      "\n",
      "        Left Upper Leg z_Acc  Left Lower Leg x_Acc  Left Lower Leg y_Acc  \\\n",
      "Minute                                                                     \n",
      "0                   0.013553              0.132128             -0.070723   \n",
      "1                  -0.005887             -0.174994              0.056990   \n",
      "2                  -0.316876              0.052290              0.253975   \n",
      "3                  -0.000004              0.095499             -0.406729   \n",
      "4                  -0.001346              0.037040              0.059038   \n",
      "...                      ...                   ...                   ...   \n",
      "2352                0.048255              0.048053             -0.083358   \n",
      "2353               -0.026518             -0.102662              0.156881   \n",
      "2354                0.009107              0.161590             -0.078252   \n",
      "2355               -0.018865             -0.300424             -0.260123   \n",
      "2356                0.016996              0.562605              0.667400   \n",
      "\n",
      "        Left Lower Leg z_Acc  Left Foot x_Acc  Left Foot y_Acc  \\\n",
      "Minute                                                           \n",
      "0                   0.009045         0.120245        -0.055962   \n",
      "1                  -0.010770        -0.115387         0.005737   \n",
      "2                  -0.032511        -0.146387         0.185996   \n",
      "3                  -0.010531         0.223051        -0.237223   \n",
      "4                   0.017141         0.023653         0.019572   \n",
      "...                      ...              ...              ...   \n",
      "2352                0.016318         0.074757        -0.066066   \n",
      "2353               -0.015750        -0.038337         0.014415   \n",
      "2354               -0.016327         0.106158        -0.037027   \n",
      "2355               -0.053406        -0.063161         0.274790   \n",
      "2356                0.069504         0.363393         0.275628   \n",
      "\n",
      "        Left Foot z_Acc  Left Toe x_Acc  Left Toe y_Acc  Left Toe z_Acc  \n",
      "Minute                                                                   \n",
      "0              0.012711        0.122279       -0.039814        0.015926  \n",
      "1             -0.008283       -0.113139        0.001427       -0.004689  \n",
      "2              0.018817       -0.173892        0.183788        0.020886  \n",
      "3             -0.059320        0.221054       -0.234018       -0.055876  \n",
      "4              0.023048        0.023015        0.020380        0.039223  \n",
      "...                 ...             ...             ...             ...  \n",
      "2352           0.021549        0.062313       -0.056839        0.022901  \n",
      "2353           0.061131       -0.054750        0.011642        0.061614  \n",
      "2354          -0.043937        0.055047       -0.049712       -0.028327  \n",
      "2355          -0.281238       -0.050034        0.217302       -0.236978  \n",
      "2356           0.365757        0.393988        0.407340        0.303664  \n",
      "\n",
      "[2357 rows x 141 columns]>\n"
     ]
    }
   ],
   "source": [
    "print (boning_p1_min.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns in the boning dataset:\n",
      "[]\n",
      "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "       ...\n",
      "       2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093],\n",
      "      dtype='int64', name='Minute', length=2094)\n"
     ]
    }
   ],
   "source": [
    "# Check for columns that are present in the minutes dataset but not in the original dataset\n",
    "def check_missing_columns(original_df, minutes_df):\n",
    "    missing_columns = [col for col in minutes_df.columns if col not in original_df.columns]\n",
    "    return missing_columns\n",
    "\n",
    "\n",
    "print(\"Missing columns in the boning dataset:\")\n",
    "print(check_missing_columns(boning_P1, boning_p1_min))\n",
    "\n",
    "print(slicing_p2_min.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Merge Boning and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boning and Slicing datasets have been successfully merged.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the converted datasets (boning and slicing) for the same person\n",
    "boning_df_p1 = pd.read_csv('bone_slice_min/J_Boning_min.csv')\n",
    "boning_df_p2 = pd.read_csv('bone_slice_min/S_Boning_min.csv')\n",
    "slicing_df_p1 = pd.read_csv('bone_slice_min/J_Slicing_min.csv')\n",
    "slicing_df_p2 = pd.read_csv('bone_slice_min/S_Slicing_min.csv')\n",
    "\n",
    "# Introduce the 'Main_Activity' column\n",
    "boning_df_P1['Main_Activity'] = '0' # 0 for Boning\n",
    "boning_df_P2['Main_Activity'] = '0'\n",
    "slicing_df_p1['Main_Activity'] = '1' # 1 for Slicing\n",
    "slicing_df_p2['Main_Activity'] = '1' \n",
    "\n",
    "# Merge the boning and slicing datasets (row-wise)\n",
    "merged_df_p1 = pd.concat([boning_df_p1, slicing_df_p1], ignore_index=True)\n",
    "merged_df_p2 = pd.concat([boning_df_p2, slicing_df_p2], ignore_index=True)\n",
    "\n",
    "# Ensure 'Main_Activity' column has no NaN values\n",
    "merged_df_p1['Main_Activity'] = merged_df_p1['Main_Activity'].fillna('0')  \n",
    "merged_df_p2['Main_Activity'] = merged_df_p2['Main_Activity'].fillna('0')  \n",
    "\n",
    "# After merging, convert 'Label' back to integer\n",
    "merged_df_p1['Label'] = merged_df_p1['Label'].astype('Int64')  # Use 'Int64' to handle NaN if any\n",
    "merged_df_p2['Label'] = merged_df_p2['Label'].astype('Int64')\n",
    "\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_df_p1.to_csv('bone_slice_merged/Worker1.csv', index=False)\n",
    "merged_df_p2.to_csv('bone_slice_merged/Worker2.csv', index=False)\n",
    "\n",
    "print(\"Boning and Slicing datasets have been successfully merged.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of       Minute  Label  Knife_Sharpness_Category  Shift  Pelvis x_Vel  \\\n",
      "0          0      4                         0      1           0.0   \n",
      "1          1      4                         0      1           0.0   \n",
      "2          2      4                         0      1           0.0   \n",
      "3          3      0                         0      1           0.0   \n",
      "4          4      0                         0      1           0.0   \n",
      "...      ...    ...                       ...    ...           ...   \n",
      "4445    2088      8                         2      1           0.0   \n",
      "4446    2089      3                         2      1           0.0   \n",
      "4447    2090      3                         2      1           0.0   \n",
      "4448    2091      3                         2      1           0.0   \n",
      "4449    2092      3                         2      1           0.0   \n",
      "\n",
      "      Pelvis y_Vel  Pelvis z_Vel  L5 x_Vel  L5 y_Vel  L5 z_Vel  ...  \\\n",
      "0              0.0           0.0  0.027806 -0.051742  0.198527  ...   \n",
      "1              0.0           0.0  0.043772 -0.035047  0.252839  ...   \n",
      "2              0.0           0.0 -0.019464  0.056012  0.228783  ...   \n",
      "3              0.0           0.0 -0.136964  0.101034  0.211410  ...   \n",
      "4              0.0           0.0 -0.040060 -0.060612  0.178886  ...   \n",
      "...            ...           ...       ...       ...       ...  ...   \n",
      "4445           0.0           0.0  0.098745 -0.003043 -3.077479  ...   \n",
      "4446           0.0           0.0  0.078221  0.059226 -3.102629  ...   \n",
      "4447           0.0           0.0 -0.078730  0.043318 -3.079259  ...   \n",
      "4448           0.0           0.0 -0.038208  0.049531 -3.105127  ...   \n",
      "4449           0.0           0.0  0.122878  0.114004 -3.121920  ...   \n",
      "\n",
      "      Left Lower Leg x_Acc  Left Lower Leg y_Acc  Left Lower Leg z_Acc  \\\n",
      "0                 0.132128             -0.070723              0.009045   \n",
      "1                -0.174994              0.056990             -0.010770   \n",
      "2                 0.052290              0.253975             -0.032511   \n",
      "3                 0.095499             -0.406729             -0.010531   \n",
      "4                 0.037040              0.059038              0.017141   \n",
      "...                    ...                   ...                   ...   \n",
      "4445             -0.088297              0.064084              0.005765   \n",
      "4446              0.012948             -0.015454              0.013032   \n",
      "4447             -0.058989              0.075561             -0.029483   \n",
      "4448              0.186131             -0.134978             -0.014432   \n",
      "4449             -0.401185              0.139288             -0.069582   \n",
      "\n",
      "      Left Foot x_Acc  Left Foot y_Acc  Left Foot z_Acc  Left Toe x_Acc  \\\n",
      "0            0.120245        -0.055962         0.012711        0.122279   \n",
      "1           -0.115387         0.005737        -0.008283       -0.113139   \n",
      "2           -0.146387         0.185996         0.018817       -0.173892   \n",
      "3            0.223051        -0.237223        -0.059320        0.221054   \n",
      "4            0.023653         0.019572         0.023048        0.023015   \n",
      "...               ...              ...              ...             ...   \n",
      "4445         0.166491        -0.102728         0.094151        0.167003   \n",
      "4446        -0.183364         0.164441        -0.044958       -0.139102   \n",
      "4447        -0.046397         0.028972        -0.022511       -0.060700   \n",
      "4448         0.129994         0.024692        -0.067364        0.123195   \n",
      "4449        -0.112478        -0.274451         0.129827       -0.120975   \n",
      "\n",
      "      Left Toe y_Acc  Left Toe z_Acc  Main_Activity  \n",
      "0          -0.039814        0.015926              0  \n",
      "1           0.001427       -0.004689              0  \n",
      "2           0.183788        0.020886              0  \n",
      "3          -0.234018       -0.055876              0  \n",
      "4           0.020380        0.039223              0  \n",
      "...              ...             ...            ...  \n",
      "4445       -0.115184        0.099068              1  \n",
      "4446        0.215035        0.012488              1  \n",
      "4447        0.021307       -0.014920              1  \n",
      "4448        0.021574       -0.063125              1  \n",
      "4449       -0.247186        0.145132              1  \n",
      "\n",
      "[4450 rows x 143 columns]>\n",
      "(4390, 143)\n",
      "Index(['Minute', 'Label', 'Knife_Sharpness_Category', 'Shift', 'Pelvis x_Vel',\n",
      "       'Pelvis y_Vel', 'Pelvis z_Vel', 'L5 x_Vel', 'L5 y_Vel', 'L5 z_Vel',\n",
      "       ...\n",
      "       'Left Lower Leg x_Acc', 'Left Lower Leg y_Acc', 'Left Lower Leg z_Acc',\n",
      "       'Left Foot x_Acc', 'Left Foot y_Acc', 'Left Foot z_Acc',\n",
      "       'Left Toe x_Acc', 'Left Toe y_Acc', 'Left Toe z_Acc', 'Main_Activity'],\n",
      "      dtype='object', length=143)\n"
     ]
    }
   ],
   "source": [
    "print(merged_df_p1.info)\n",
    "print(merged_df_p2.shape)\n",
    "\n",
    "print(merged_df_p1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Merge P1 and P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as 'AllWorkers.csv'.\n",
      "(8840, 144)\n",
      "<bound method DataFrame.info of       Minute  Label  Knife_Sharpness_Category  Shift  Pelvis x_Vel  \\\n",
      "0          0      4                         0      1           0.0   \n",
      "1          1      4                         0      1           0.0   \n",
      "2          2      4                         0      1           0.0   \n",
      "3          3      0                         0      1           0.0   \n",
      "4          4      0                         0      1           0.0   \n",
      "...      ...    ...                       ...    ...           ...   \n",
      "8835    2089      4                         2      1           0.0   \n",
      "8836    2090      4                         2      1           0.0   \n",
      "8837    2091      4                         2      1           0.0   \n",
      "8838    2092      7                         2      1           0.0   \n",
      "8839    2093      7                         2      1           0.0   \n",
      "\n",
      "      Pelvis y_Vel  Pelvis z_Vel  L5 x_Vel  L5 y_Vel  L5 z_Vel  ...  \\\n",
      "0              0.0           0.0  0.027806 -0.051742  0.198527  ...   \n",
      "1              0.0           0.0  0.043772 -0.035047  0.252839  ...   \n",
      "2              0.0           0.0 -0.019464  0.056012  0.228783  ...   \n",
      "3              0.0           0.0 -0.136964  0.101034  0.211410  ...   \n",
      "4              0.0           0.0 -0.040060 -0.060612  0.178886  ...   \n",
      "...            ...           ...       ...       ...       ...  ...   \n",
      "8835           0.0           0.0 -0.065690  0.089202 -4.904478  ...   \n",
      "8836           0.0           0.0 -0.042336  0.017970 -4.926291  ...   \n",
      "8837           0.0           0.0 -0.003401 -0.040075 -4.926952  ...   \n",
      "8838           0.0           0.0  0.030334 -0.120449 -4.923528  ...   \n",
      "8839           0.0           0.0 -0.018232  0.063159 -4.950528  ...   \n",
      "\n",
      "      Left Lower Leg y_Acc  Left Lower Leg z_Acc  Left Foot x_Acc  \\\n",
      "0                -0.070723              0.009045         0.120245   \n",
      "1                 0.056990             -0.010770        -0.115387   \n",
      "2                 0.253975             -0.032511        -0.146387   \n",
      "3                -0.406729             -0.010531         0.223051   \n",
      "4                 0.059038              0.017141         0.023653   \n",
      "...                    ...                   ...              ...   \n",
      "8835             -0.101567              0.025192         0.037240   \n",
      "8836              0.000188              0.030591        -0.038358   \n",
      "8837             -0.089840             -0.002493        -0.015311   \n",
      "8838              0.065539              0.004687         0.140735   \n",
      "8839              0.190441             -0.055680        -0.352803   \n",
      "\n",
      "      Left Foot y_Acc  Left Foot z_Acc  Left Toe x_Acc  Left Toe y_Acc  \\\n",
      "0           -0.055962         0.012711        0.122279       -0.039814   \n",
      "1            0.005737        -0.008283       -0.113139        0.001427   \n",
      "2            0.185996         0.018817       -0.173892        0.183788   \n",
      "3           -0.237223        -0.059320        0.221054       -0.234018   \n",
      "4            0.019572         0.023048        0.023015        0.020380   \n",
      "...               ...              ...             ...             ...   \n",
      "8835        -0.077497         0.057873        0.039352       -0.074440   \n",
      "8836        -0.072110         0.024171       -0.037835       -0.078184   \n",
      "8837        -0.092067        -0.008872       -0.018001       -0.097658   \n",
      "8838        -0.016792         0.003696        0.144400       -0.039035   \n",
      "8839         0.226670        -0.060860       -0.327187        0.223883   \n",
      "\n",
      "      Left Toe z_Acc  Main_Activity  Worker  \n",
      "0           0.015926              0       1  \n",
      "1          -0.004689              0       1  \n",
      "2           0.020886              0       1  \n",
      "3          -0.055876              0       1  \n",
      "4           0.039223              0       1  \n",
      "...              ...            ...     ...  \n",
      "8835        0.062926              1       2  \n",
      "8836        0.024799              1       2  \n",
      "8837        0.004893              1       2  \n",
      "8838        0.015139              1       2  \n",
      "8839       -0.028188              1       2  \n",
      "\n",
      "[8840 rows x 144 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Merge person1.csv and person2.csv\n",
    "person1_df = pd.read_csv('bone_slice_merged/Worker1.csv')\n",
    "person2_df = pd.read_csv('bone_slice_merged/Worker2.csv')\n",
    "\n",
    "# introduce new column 'Worker' to identify the person\n",
    "person1_df['Worker'] = 1\n",
    "person2_df['Worker'] = 2\n",
    "\n",
    "# Merge the datasets for Worker 1 and Worker 2\n",
    "merged_df = pd.concat([person1_df, person2_df], ignore_index=True)\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_df.to_csv('bone_slice_merged/AllWorkers.csv', index=False)\n",
    "\n",
    "print (\"Merged dataset saved as 'AllWorkers.csv'.\")\n",
    "\n",
    "print(merged_df.shape)\n",
    "print(merged_df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
