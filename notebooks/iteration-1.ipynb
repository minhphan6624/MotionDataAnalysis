{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "sys.path.append('../')  # Go up one directory\n",
    "\n",
    "from src.data_splitting import split_data, get_split_shapes\n",
    "from src.model_training import get_models, train_models_for_task\n",
    "from src.model_evaluation import print_results, print_result_for_task, summarize_results, plot_confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load and split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7956, 135)\n",
      "\n",
      "main_activity splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "label splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "sharpness splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "cleaned_df = pd.read_csv('..\\\\data\\\\final_data\\\\cleaned_train_data.csv')\n",
    "print(f\"Dataset shape: {cleaned_df.shape}\")\n",
    "\n",
    "# Shuffle the data\n",
    "cleaned_df = cleaned_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "splits = split_data(cleaned_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(get_split_shapes(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Train and evaluate models for each target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline models...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining baseline models...\")\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Main activity (Boning/Slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Main Activity Models...\n",
      "\n",
      "Training models for Main Activity...\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = splits['main_activity']\n",
    "\n",
    "results['main_activity'] = train_models_for_task(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    task_type='binary',\n",
    "    task_name='Main Activity'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Label/Sub-activity (Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models for Label...\n",
      "\n",
      "Training Decision Tree...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = splits['label']\n",
    "results['label'] = train_models_for_task(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    task_type='multiclass',\n",
    "    task_name='Label'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Knife Sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models for Knife Sharpness...\n",
      "\n",
      "Training Decision Tree...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = splits['sharpness']\n",
    "\n",
    "results['sharpness'] = train_models_for_task(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    task_type='three_class',\n",
    "    task_name='Knife Sharpness'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for main_activity:\n",
      "--------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.8172\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       838\n",
      "           1       0.81      0.80      0.81       754\n",
      "\n",
      "    accuracy                           0.82      1592\n",
      "   macro avg       0.82      0.82      0.82      1592\n",
      "weighted avg       0.82      0.82      0.82      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[696 142]\n",
      " [149 605]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9102\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       838\n",
      "           1       0.92      0.88      0.90       754\n",
      "\n",
      "    accuracy                           0.91      1592\n",
      "   macro avg       0.91      0.91      0.91      1592\n",
      "weighted avg       0.91      0.91      0.91      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[783  55]\n",
      " [ 88 666]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.9454\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       838\n",
      "           1       0.95      0.94      0.94       754\n",
      "\n",
      "    accuracy                           0.95      1592\n",
      "   macro avg       0.95      0.95      0.95      1592\n",
      "weighted avg       0.95      0.95      0.95      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[797  41]\n",
      " [ 46 708]]\n",
      "\n",
      "Results for label:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.4378\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.47      0.46       191\n",
      "           1       0.26      0.28      0.27        43\n",
      "           2       0.34      0.38      0.36       150\n",
      "           3       0.14      0.15      0.15        72\n",
      "           4       0.60      0.59      0.60       797\n",
      "           5       0.20      0.18      0.19       184\n",
      "           6       0.21      0.14      0.17        21\n",
      "           7       0.00      0.00      0.00        26\n",
      "           8       0.16      0.16      0.16       108\n",
      "\n",
      "    accuracy                           0.44      1592\n",
      "   macro avg       0.26      0.26      0.26      1592\n",
      "weighted avg       0.44      0.44      0.44      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 89   6  21   3  56   8   0   1   7]\n",
      " [  5  12   2   2  13   4   0   1   4]\n",
      " [ 25   4  57   5  41  14   0   0   4]\n",
      " [  8   4   4  11  30   5   0   3   7]\n",
      " [ 56  14  57  39 474  86   7  15  49]\n",
      " [  8   1  13   6  99  34   3   2  18]\n",
      " [  1   0   0   1  11   3   3   1   1]\n",
      " [  0   2   2   2  15   3   0   0   2]\n",
      " [  6   4  10   7  49  13   1   1  17]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6300\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.58      0.66       191\n",
      "           1       0.43      0.60      0.50        43\n",
      "           2       0.76      0.51      0.61       150\n",
      "           3       0.36      0.12      0.19        72\n",
      "           4       0.64      0.90      0.75       797\n",
      "           5       0.39      0.20      0.27       184\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       0.30      0.12      0.17        26\n",
      "           8       0.49      0.19      0.27       108\n",
      "\n",
      "    accuracy                           0.63      1592\n",
      "   macro avg       0.46      0.36      0.38      1592\n",
      "weighted avg       0.60      0.63      0.59      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[110  13   7   1  56   2   0   0   2]\n",
      " [  2  26   1   2  10   0   0   0   2]\n",
      " [  9  10  77   2  48   3   0   0   1]\n",
      " [  6   7   1   9  40   5   0   1   3]\n",
      " [ 10   0  12   5 721  37   1   2   9]\n",
      " [  0   0   1   1 139  37   0   2   4]\n",
      " [  0   0   0   0  19   2   0   0   0]\n",
      " [  0   0   0   2  17   3   1   3   0]\n",
      " [  3   4   2   3  68   6   0   2  20]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.6558\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67       191\n",
      "           1       0.50      0.23      0.32        43\n",
      "           2       0.84      0.59      0.70       150\n",
      "           3       0.48      0.14      0.22        72\n",
      "           4       0.65      0.95      0.77       797\n",
      "           5       0.47      0.16      0.24       184\n",
      "           6       0.00      0.00      0.00        21\n",
      "           7       1.00      0.15      0.27        26\n",
      "           8       0.57      0.27      0.36       108\n",
      "\n",
      "    accuracy                           0.66      1592\n",
      "   macro avg       0.58      0.35      0.39      1592\n",
      "weighted avg       0.64      0.66      0.61      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117   4   8   2  52   2   0   0   6]\n",
      " [  9  10   0   2  21   0   0   0   1]\n",
      " [ 11   3  89   1  45   1   0   0   0]\n",
      " [  7   2   0  10  46   2   0   0   5]\n",
      " [  8   0   6   1 756  21   0   0   5]\n",
      " [  1   0   1   3 147  29   0   0   3]\n",
      " [  0   0   0   0  19   1   0   0   1]\n",
      " [  0   0   0   0  21   0   0   4   1]\n",
      " [  5   1   2   2  63   6   0   0  29]]\n",
      "\n",
      "Results for sharpness:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.4987\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.26      0.26       270\n",
      "           1       0.52      0.53      0.53       621\n",
      "           2       0.57      0.56      0.56       701\n",
      "\n",
      "    accuracy                           0.50      1592\n",
      "   macro avg       0.45      0.45      0.45      1592\n",
      "weighted avg       0.50      0.50      0.50      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 70  94 106]\n",
      " [ 94 332 195]\n",
      " [101 208 392]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6068\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40       270\n",
      "           1       0.60      0.64      0.62       621\n",
      "           2       0.64      0.68      0.66       701\n",
      "\n",
      "    accuracy                           0.61      1592\n",
      "   macro avg       0.58      0.55      0.56      1592\n",
      "weighted avg       0.60      0.61      0.60      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 90  88  92]\n",
      " [ 41 398 182]\n",
      " [ 50 173 478]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.6250\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.26      0.36       270\n",
      "           1       0.62      0.66      0.64       621\n",
      "           2       0.63      0.74      0.68       701\n",
      "\n",
      "    accuracy                           0.62      1592\n",
      "   macro avg       0.61      0.55      0.56      1592\n",
      "weighted avg       0.62      0.62      0.61      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 69  89 112]\n",
      " [ 22 409 190]\n",
      " [ 27 157 517]]\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Plotting confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nPlotting confusion matrices...\")\n",
    "plot_confusion_matrices(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results for Main_activity Models\n",
      "Logistic Regression: Mean CV Accuracy = 0.8251, Std Dev = 0.0130\n",
      "Random Forest: Mean CV Accuracy = 0.9134, Std Dev = 0.0162\n",
      "XGBoost: Mean CV Accuracy = 0.9441, Std Dev = 0.0087\n",
      "\n",
      "Cross-Validation Results for Label Models\n",
      "Decision Tree: Mean CV Accuracy = 0.4312, Std Dev = 0.0179\n",
      "Random Forest: Mean CV Accuracy = 0.6183, Std Dev = 0.0136\n",
      "XGBoost: Mean CV Accuracy = 0.6410, Std Dev = 0.0121\n",
      "\n",
      "Cross-Validation Results for Sharpness Models\n",
      "Decision Tree: Mean CV Accuracy = 0.4868, Std Dev = 0.0289\n",
      "Random Forest: Mean CV Accuracy = 0.5952, Std Dev = 0.0116\n",
      "XGBoost: Mean CV Accuracy = 0.6125, Std Dev = 0.0106\n"
     ]
    }
   ],
   "source": [
    "from src.model_evaluation import cross_validate_model\n",
    "\n",
    "# Train baseline models for each target and print cross-validation results\n",
    "for target, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    print(f\"\\nCross-Validation Results for {target.capitalize()} Models\")\n",
    "    \n",
    "\n",
    "    if target == 'main_activity':\n",
    "        models = get_models('binary')  # Retrieve models for the specific task\n",
    "    else:\n",
    "        models = get_models('multiclass')\n",
    "    for model_name, model in models.items():\n",
    "        mean_cv_score, std_cv_score = cross_validate_model(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        print(f\"{model_name}: Mean CV Accuracy = {mean_cv_score:.4f}, Std Dev = {std_cv_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for main_activity:\n",
      "--------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.8218\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9299\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.9531\n",
      "\n",
      "Results for label:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.4005\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.5837\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.6431\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "summary = summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Feature Importance Analysis (for tree-based models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_importance(model, feature_names, title):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(f\"Feature Importances ({title})\")\n",
    "        plt.bar(range(len(indices[:20])), importances[indices[:20]])\n",
    "        plt.xticks(range(len(indices[:20])), [feature_names[i] for i in indices[:20]], rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Plot feature importance for best models (if tree-based)\n",
    "feature_names = [col for col in cleaned_df.columns \n",
    "                if col not in ['Main_Activity', 'Label', 'Knife_Sharpness_Category']]\n",
    "\n",
    "for task in results:\n",
    "    best_model_name = summary[task]['best_model']\n",
    "    best_model = results[task][best_model_name]['model']\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        plot_feature_importance(best_model, feature_names, f\"{task} - {best_model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
