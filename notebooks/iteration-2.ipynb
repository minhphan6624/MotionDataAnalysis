{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "sys.path.append('../')  # Go up one directory\n",
    "\n",
    "from src.data_splitting import split_data, get_split_shapes\n",
    "from src.model_training import get_models\n",
    "from src.model_evaluation import print_results, print_result_for_task, summarize_results, plot_confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7956, 135)\n",
      "\n",
      "main_activity splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "label splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "sharpness splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "cleaned_df = pd.read_csv('..\\\\data\\\\final_data\\\\cleaned_train_data.csv')\n",
    "print(f\"Dataset shape: {cleaned_df.shape}\")\n",
    "\n",
    "# Shuffle the data\n",
    "cleaned_df = cleaned_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "splits = split_data(cleaned_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(get_split_shapes(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Main_activity\n",
      "Original class distribution: {0: np.int64(3350), 1: np.int64(3014)}\n",
      "Resampled class distribution: {1: np.int64(3291), 0: np.int64(3291)}\n",
      "\n",
      "Target: Label\n",
      "Original class distribution: {4: np.int64(3187), 0: np.int64(765), 5: np.int64(733), 2: np.int64(598), 8: np.int64(433), 3: np.int64(290), 1: np.int64(170), 7: np.int64(103), 6: np.int64(85)}\n",
      "Resampled class distribution: {0: np.int64(3187), 3: np.int64(3187), 1: np.int64(3187), 7: np.int64(3187), 2: np.int64(3187), 6: np.int64(3187), 8: np.int64(3187), 4: np.int64(3186), 5: np.int64(3186)}\n",
      "\n",
      "Target: Sharpness\n",
      "Original class distribution: {2: np.int64(2802), 1: np.int64(2481), 0: np.int64(1081)}\n",
      "Resampled class distribution: {0: np.int64(2792), 2: np.int64(2692), 1: np.int64(2684)}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Initialize SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "\n",
    "# Loop through each target variable to apply SMOTE-Tomek\n",
    "balanced_data = {}\n",
    "for target in ['main_activity', 'label', 'sharpness']:  # Adjust based on your target variable names\n",
    "    X_train, X_test, y_train, y_test = splits[target]\n",
    "    X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "    balanced_data[target] = (X_resampled, X_test, y_resampled, y_test)\n",
    "    print(f\"\\nTarget: {target.capitalize()}\")\n",
    "    print(f\"Original class distribution: {dict(pd.Series(y_train).value_counts())}\")\n",
    "    print(f\"Resampled class distribution: {dict(pd.Series(y_resampled).value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete for Main_activity\n",
      "Normalization complete for Label\n",
      "Normalization complete for Sharpness\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = {}\n",
    "\n",
    "# Loop through balanced data and normalize\n",
    "for target, (X_resampled, X_test, y_resampled, y_test) in balanced_data.items():\n",
    "    X_normalized = scaler.fit_transform(X_resampled)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    normalized_data[target] = (X_normalized, X_test_normalized, y_resampled, y_test)\n",
    "    print(f\"Normalization complete for {target.capitalize()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6582, 132)\n"
     ]
    }
   ],
   "source": [
    "print (normalized_data['main_activity'][0].shape)\n",
    "# print (normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train models based on Balanced and Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models for Target: Main_activity\n",
      "\n",
      "Training Models for Target: Label\n",
      "\n",
      "Training Models for Target: Sharpness\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Dictionary to store results for each target\n",
    "results = {}\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(f\"\\nTraining Models for Target: {target.capitalize()}\")\n",
    "\n",
    "    if target == 'main_activity':\n",
    "        models = get_models(task_type='binary')\n",
    "    else:\n",
    "        models = get_models(task_type=\"others\")  \n",
    "\n",
    "    # dict to store results for each model\n",
    "    target_trained_models = {}\n",
    "    target_results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        # Train each model\n",
    "        model.fit(X_train, y_train)\n",
    "        target_trained_models[model_name] = model # Store trained model\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Store all metrics in the results dictionary\n",
    "        target_results[model_name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'report': class_report,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "      \n",
    "    # Store results for the target\n",
    "    results[target] = target_results\n",
    "    trained_models[target] = target_trained_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for main_activity:\n",
      "--------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.8386\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       838\n",
      "           1       0.81      0.85      0.83       754\n",
      "\n",
      "    accuracy                           0.84      1592\n",
      "   macro avg       0.84      0.84      0.84      1592\n",
      "weighted avg       0.84      0.84      0.84      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[691 147]\n",
      " [110 644]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9114\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       838\n",
      "           1       0.91      0.90      0.91       754\n",
      "\n",
      "    accuracy                           0.91      1592\n",
      "   macro avg       0.91      0.91      0.91      1592\n",
      "weighted avg       0.91      0.91      0.91      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[775  63]\n",
      " [ 78 676]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.9460\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       838\n",
      "           1       0.94      0.94      0.94       754\n",
      "\n",
      "    accuracy                           0.95      1592\n",
      "   macro avg       0.95      0.95      0.95      1592\n",
      "weighted avg       0.95      0.95      0.95      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[796  42]\n",
      " [ 44 710]]\n",
      "\n",
      "Results for label:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.3354\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41       191\n",
      "           1       0.12      0.23      0.16        43\n",
      "           2       0.32      0.45      0.37       150\n",
      "           3       0.07      0.14      0.09        72\n",
      "           4       0.64      0.38      0.48       797\n",
      "           5       0.17      0.21      0.19       184\n",
      "           6       0.02      0.05      0.03        21\n",
      "           7       0.02      0.04      0.02        26\n",
      "           8       0.14      0.22      0.17       108\n",
      "\n",
      "    accuracy                           0.34      1592\n",
      "   macro avg       0.21      0.24      0.21      1592\n",
      "weighted avg       0.44      0.34      0.37      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78  14  24  13  33  12   1   2  14]\n",
      " [  5  10   6   7   7   4   0   0   4]\n",
      " [ 20   6  67  11  20  12   3   1  10]\n",
      " [  4   6   7  10  18  14   2   3   8]\n",
      " [ 68  31  78  72 305 105  25  34  79]\n",
      " [ 12   8  14  15  53  38   4  11  29]\n",
      " [  1   1   3   2   5   4   1   1   3]\n",
      " [  1   0   2   2   7   8   2   1   3]\n",
      " [  2   5   7   9  27  24   4   6  24]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6080\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.51      0.63       191\n",
      "           1       0.32      0.60      0.42        43\n",
      "           2       0.73      0.55      0.63       150\n",
      "           3       0.33      0.28      0.30        72\n",
      "           4       0.70      0.77      0.73       797\n",
      "           5       0.42      0.43      0.43       184\n",
      "           6       0.38      0.24      0.29        21\n",
      "           7       0.24      0.31      0.27        26\n",
      "           8       0.36      0.34      0.35       108\n",
      "\n",
      "    accuracy                           0.61      1592\n",
      "   macro avg       0.48      0.45      0.45      1592\n",
      "weighted avg       0.62      0.61      0.61      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 97  24   9   5  45   5   0   1   5]\n",
      " [  0  26   0   2  12   0   0   0   3]\n",
      " [  3  14  83   5  35   8   0   0   2]\n",
      " [  2   4   1  20  32   3   0   2   8]\n",
      " [ 14   5  17  13 613  82   5  11  37]\n",
      " [  1   3   0   5  72  79   2  11  11]\n",
      " [  0   0   0   0  13   2   5   1   0]\n",
      " [  0   0   0   1  15   1   0   8   1]\n",
      " [  1   6   3  10  44   6   1   0  37]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.6149\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.57      0.67       191\n",
      "           1       0.40      0.60      0.48        43\n",
      "           2       0.73      0.63      0.68       150\n",
      "           3       0.32      0.33      0.33        72\n",
      "           4       0.70      0.77      0.73       797\n",
      "           5       0.37      0.33      0.35       184\n",
      "           6       0.40      0.19      0.26        21\n",
      "           7       0.16      0.15      0.16        26\n",
      "           8       0.38      0.43      0.40       108\n",
      "\n",
      "    accuracy                           0.61      1592\n",
      "   macro avg       0.48      0.45      0.45      1592\n",
      "weighted avg       0.62      0.61      0.61      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  15  13   5  38   2   0   0   9]\n",
      " [  0  26   0   4  10   0   0   0   3]\n",
      " [  2  10  95   7  28   4   0   0   4]\n",
      " [  0   6   2  24  26   5   0   2   7]\n",
      " [ 16   5  18  19 610  80   3  11  35]\n",
      " [  2   1   1   6  88  61   2   8  15]\n",
      " [  1   0   0   2   8   5   4   0   1]\n",
      " [  0   0   0   0  19   1   0   4   2]\n",
      " [  2   2   2   8  39   8   1   0  46]]\n",
      "\n",
      "Results for sharpness:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.4686\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.38      0.33       270\n",
      "           1       0.50      0.50      0.50       621\n",
      "           2       0.54      0.47      0.50       701\n",
      "\n",
      "    accuracy                           0.47      1592\n",
      "   macro avg       0.44      0.45      0.44      1592\n",
      "weighted avg       0.48      0.47      0.47      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103  88  79]\n",
      " [105 313 203]\n",
      " [149 222 330]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.5892\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.40      0.41       270\n",
      "           1       0.60      0.60      0.60       621\n",
      "           2       0.64      0.65      0.64       701\n",
      "\n",
      "    accuracy                           0.59      1592\n",
      "   macro avg       0.55      0.55      0.55      1592\n",
      "weighted avg       0.59      0.59      0.59      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  78  83]\n",
      " [ 73 374 174]\n",
      " [ 78 168 455]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.5980\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.46      0.43       270\n",
      "           1       0.62      0.63      0.63       621\n",
      "           2       0.68      0.62      0.65       701\n",
      "\n",
      "    accuracy                           0.60      1592\n",
      "   macro avg       0.56      0.57      0.57      1592\n",
      "weighted avg       0.61      0.60      0.60      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[125  76  69]\n",
      " [ 88 394 139]\n",
      " [101 167 433]]\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting confusion matrices...\")\n",
    "plot_confusion_matrices(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validating Models for Target: Main_activity\n",
      "Decision Tree - Mean CV Accuracy: 0.7990, Std Dev: 0.0033\n",
      "Random Forest - Mean CV Accuracy: 0.9248, Std Dev: 0.0028\n",
      "XGBoost - Mean CV Accuracy: 0.9572, Std Dev: 0.0027\n",
      "\n",
      "Cross-Validating Models for Target: Label\n",
      "Decision Tree - Mean CV Accuracy: 0.7855, Std Dev: 0.0120\n",
      "Random Forest - Mean CV Accuracy: 0.9579, Std Dev: 0.0089\n",
      "XGBoost - Mean CV Accuracy: 0.9495, Std Dev: 0.0247\n",
      "\n",
      "Cross-Validating Models for Target: Sharpness\n",
      "Decision Tree - Mean CV Accuracy: 0.5702, Std Dev: 0.0326\n",
      "Random Forest - Mean CV Accuracy: 0.7077, Std Dev: 0.0428\n",
      "XGBoost - Mean CV Accuracy: 0.7159, Std Dev: 0.0587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validate each model\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(f\"\\nCross-Validating Models for Target: {target.capitalize()}\")\n",
    "    models = get_models(target)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"{model_name} - Mean CV Accuracy: {cv_scores.mean():.4f}, Std Dev: {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance(model, feature_names, target_name):\n",
    "    importances = model.feature_importances_\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot the top 10 important features\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'][:10], importance_df['Importance'][:10], color='skyblue')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Top 10 Feature Importances for {target_name}\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance for Target: Main_activity\n",
      "\n",
      "Decision Tree Feature Importance for Main_activity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Feature Importance for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mplot_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapitalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support feature importances.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[65], line 6\u001b[0m, in \u001b[0;36mplot_feature_importance\u001b[1;34m(model, feature_names, target_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_feature_importance\u001b[39m(model, feature_names, target_name):\n\u001b[0;32m      5\u001b[0m     importances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[1;32m----> 6\u001b[0m     importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportances\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     importance_df \u001b[38;5;241m=\u001b[39m importance_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Plot the top 10 important features\u001b[39;00m\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Display feature importance plots for tree-based models (Random Forest and XGBoost)\n",
    "for target, models in trained_models.items():\n",
    "    print(f\"\\nFeature Importance for Target: {target.capitalize()}\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Only plot feature importance for models that support it\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            print(f\"\\n{model_name} Feature Importance for {target.capitalize()}\")\n",
    "            plot_feature_importance(model, X_train, target_name=target.capitalize())\n",
    "        else:\n",
    "            print(f\"{model_name} does not support feature importances.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
