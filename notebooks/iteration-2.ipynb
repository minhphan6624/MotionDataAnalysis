{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "sys.path.append('../')  # Go up one directory\n",
    "\n",
    "from src.data_splitting import split_data, get_split_shapes\n",
    "from src.model_training import get_models, train_models_for_task\n",
    "from src.model_evaluation import print_results, print_result_for_task, summarize_results, plot_confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8840, 135)\n",
      "\n",
      "main_activity splits:\n",
      "X_train shape: (7072, 132)\n",
      "X_test shape: (1768, 132)\n",
      "y_train shape: (7072,)\n",
      "y_test shape: (1768,)\n",
      "\n",
      "label splits:\n",
      "X_train shape: (7072, 132)\n",
      "X_test shape: (1768, 132)\n",
      "y_train shape: (7072,)\n",
      "y_test shape: (1768,)\n",
      "\n",
      "sharpness splits:\n",
      "X_train shape: (7072, 132)\n",
      "X_test shape: (1768, 132)\n",
      "y_train shape: (7072,)\n",
      "y_test shape: (1768,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "cleaned_df = pd.read_csv('..\\\\data\\\\final_data\\\\cleaned_allworkers.csv')\n",
    "print(f\"Dataset shape: {cleaned_df.shape}\")\n",
    "\n",
    "# Shuffle the data\n",
    "cleaned_df = cleaned_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "splits = split_data(cleaned_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(get_split_shapes(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Main_activity\n",
      "Original class distribution: {0: np.int64(3722), 1: np.int64(3350)}\n",
      "Resampled class distribution: {1: np.int64(3665), 0: np.int64(3665)}\n",
      "\n",
      "Target: Label\n",
      "Original class distribution: {4: np.int64(3529), 0: np.int64(857), 5: np.int64(815), 2: np.int64(665), 8: np.int64(487), 3: np.int64(313), 1: np.int64(195), 7: np.int64(114), 6: np.int64(97)}\n",
      "Resampled class distribution: {2: np.int64(3529), 3: np.int64(3529), 8: np.int64(3529), 1: np.int64(3529), 7: np.int64(3529), 6: np.int64(3529), 0: np.int64(3528), 5: np.int64(3526), 4: np.int64(3525)}\n",
      "\n",
      "Target: Sharpness\n",
      "Original class distribution: {2: np.int64(3094), 1: np.int64(2771), 0: np.int64(1207)}\n",
      "Resampled class distribution: {0: np.int64(3082), 2: np.int64(2956), 1: np.int64(2950)}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Initialize SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "\n",
    "# Loop through each target variable to apply SMOTE-Tomek\n",
    "balanced_data = {}\n",
    "for target in ['main_activity', 'label', 'sharpness']:  # Adjust based on your target variable names\n",
    "    X_train, X_test, y_train, y_test = splits[target]\n",
    "    X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "    balanced_data[target] = (X_resampled, X_test, y_resampled, y_test)\n",
    "    print(f\"\\nTarget: {target.capitalize()}\")\n",
    "    print(f\"Original class distribution: {dict(pd.Series(y_train).value_counts())}\")\n",
    "    print(f\"Resampled class distribution: {dict(pd.Series(y_resampled).value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete for Main_activity\n",
      "Normalization complete for Label\n",
      "Normalization complete for Sharpness\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = {}\n",
    "\n",
    "# Loop through balanced data and normalize\n",
    "for target, (X_resampled, X_test, y_resampled, y_test) in balanced_data.items():\n",
    "    X_normalized = scaler.fit_transform(X_resampled)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    normalized_data[target] = (X_normalized, X_test_normalized, y_resampled, y_test)\n",
    "    print(f\"Normalization complete for {target.capitalize()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7330, 132)\n"
     ]
    }
   ],
   "source": [
    "print (normalized_data['main_activity'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train models based on Balanced and Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Models for Target: Main_activity\n",
      "\n",
      "Training Models for Target: Label\n",
      "\n",
      "Training Models for Target: Sharpness\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Dictionary to store results for each target\n",
    "results = {}\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(f\"\\nTraining Models for Target: {target.capitalize()}\")\n",
    "    models = get_models(target)  # Get models specific to this target\n",
    "\n",
    "    target_trained_models = {}\n",
    "\n",
    "    # Cross-validate each model\n",
    "    target_results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        # Train each model\n",
    "        model.fit(X_train, y_train)\n",
    "        target_trained_models[model_name] = model\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Store all metrics in the results dictionary\n",
    "        target_results[model_name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'report': class_report,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "      \n",
    "    # Store results for the target\n",
    "    results[target] = target_results\n",
    "    trained_models[target] = target_trained_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for main_activity:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.8196\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       931\n",
      "           1       0.82      0.80      0.81       837\n",
      "\n",
      "    accuracy                           0.82      1768\n",
      "   macro avg       0.82      0.82      0.82      1768\n",
      "weighted avg       0.82      0.82      0.82      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[780 151]\n",
      " [168 669]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9225\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       931\n",
      "           1       0.92      0.91      0.92       837\n",
      "\n",
      "    accuracy                           0.92      1768\n",
      "   macro avg       0.92      0.92      0.92      1768\n",
      "weighted avg       0.92      0.92      0.92      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[869  62]\n",
      " [ 75 762]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.9536\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       931\n",
      "           1       0.96      0.95      0.95       837\n",
      "\n",
      "    accuracy                           0.95      1768\n",
      "   macro avg       0.95      0.95      0.95      1768\n",
      "weighted avg       0.95      0.95      0.95      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[894  37]\n",
      " [ 45 792]]\n",
      "\n",
      "Results for label:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.3405\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.38      0.38       214\n",
      "           1       0.11      0.20      0.15        49\n",
      "           2       0.36      0.47      0.41       166\n",
      "           3       0.12      0.23      0.16        78\n",
      "           4       0.62      0.38      0.47       883\n",
      "           5       0.22      0.29      0.25       204\n",
      "           6       0.08      0.17      0.11        24\n",
      "           7       0.02      0.07      0.04        28\n",
      "           8       0.10      0.13      0.11       122\n",
      "\n",
      "    accuracy                           0.34      1768\n",
      "   macro avg       0.22      0.26      0.23      1768\n",
      "weighted avg       0.43      0.34      0.37      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 82  14  26  12  45  14   2   2  17]\n",
      " [  9  10   5   2  10   4   0   1   8]\n",
      " [ 24   5  78   9  23   9   2   9   7]\n",
      " [  7   8   7  18  16  10   0   2  10]\n",
      " [ 72  33  70  75 332 148  31  41  81]\n",
      " [ 14   8  15  15  57  60   8   9  18]\n",
      " [  0   0   1   4   8   1   4   4   2]\n",
      " [  0   2   3   2   7   8   2   2   2]\n",
      " [  9   7  11   9  39  18   2  11  16]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.5945\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.62       214\n",
      "           1       0.40      0.49      0.44        49\n",
      "           2       0.67      0.49      0.56       166\n",
      "           3       0.32      0.24      0.28        78\n",
      "           4       0.67      0.80      0.73       883\n",
      "           5       0.33      0.31      0.32       204\n",
      "           6       0.12      0.04      0.06        24\n",
      "           7       0.06      0.04      0.04        28\n",
      "           8       0.38      0.31      0.34       122\n",
      "\n",
      "    accuracy                           0.59      1768\n",
      "   macro avg       0.41      0.36      0.38      1768\n",
      "weighted avg       0.58      0.59      0.58      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[115  14  19   3  45   7   1   0  10]\n",
      " [  2  24   0   3  19   0   0   0   1]\n",
      " [ 18   6  81   7  40   9   0   0   5]\n",
      " [  4   5   0  19  34   7   0   1   8]\n",
      " [ 14   7  19  14 709  87   2   5  26]\n",
      " [  1   1   2   3 114  63   4   8   8]\n",
      " [  0   0   0   0  15   6   1   1   1]\n",
      " [  0   0   0   0  21   4   0   1   2]\n",
      " [  2   3   0  11  57  10   0   1  38]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.6386\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66       214\n",
      "           1       0.43      0.41      0.42        49\n",
      "           2       0.77      0.59      0.67       166\n",
      "           3       0.40      0.36      0.38        78\n",
      "           4       0.69      0.84      0.76       883\n",
      "           5       0.43      0.34      0.38       204\n",
      "           6       0.18      0.08      0.11        24\n",
      "           7       0.11      0.07      0.09        28\n",
      "           8       0.47      0.34      0.39       122\n",
      "\n",
      "    accuracy                           0.64      1768\n",
      "   macro avg       0.47      0.40      0.43      1768\n",
      "weighted avg       0.62      0.64      0.62      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[128  12  13   6  41   3   1   0  10]\n",
      " [  5  20   1   2  18   0   0   0   3]\n",
      " [ 16   4  98   2  37   1   0   1   7]\n",
      " [  4   4   2  28  30   2   1   3   4]\n",
      " [ 17   4  11  10 740  73   4   6  18]\n",
      " [  1   0   2   5 113  70   3   5   5]\n",
      " [  0   0   0   1  19   2   2   0   0]\n",
      " [  0   0   0   1  23   2   0   2   0]\n",
      " [  4   3   0  15  47  10   0   2  41]]\n",
      "\n",
      "Results for sharpness:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.4723\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33       302\n",
      "           1       0.52      0.50      0.51       693\n",
      "           2       0.54      0.48      0.51       773\n",
      "\n",
      "    accuracy                           0.47      1768\n",
      "   macro avg       0.45      0.46      0.45      1768\n",
      "weighted avg       0.49      0.47      0.48      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[118  80 104]\n",
      " [135 345 213]\n",
      " [168 233 372]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.39      0.41       302\n",
      "           1       0.63      0.64      0.63       693\n",
      "           2       0.64      0.65      0.65       773\n",
      "\n",
      "    accuracy                           0.60      1768\n",
      "   macro avg       0.57      0.56      0.56      1768\n",
      "weighted avg       0.60      0.60      0.60      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117  80 105]\n",
      " [ 71 444 178]\n",
      " [ 86 182 505]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.6114\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.39      0.41       302\n",
      "           1       0.64      0.64      0.64       693\n",
      "           2       0.66      0.67      0.66       773\n",
      "\n",
      "    accuracy                           0.61      1768\n",
      "   macro avg       0.57      0.57      0.57      1768\n",
      "weighted avg       0.61      0.61      0.61      1768\n",
      "\n",
      "Confusion Matrix:\n",
      "[[119  86  97]\n",
      " [ 77 444 172]\n",
      " [ 89 166 518]]\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting confusion matrices...\")\n",
    "plot_confusion_matrices(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validating Models for Target: Main_activity\n",
      "Decision Tree - Mean CV Accuracy: 0.7990, Std Dev: 0.0033\n",
      "Random Forest - Mean CV Accuracy: 0.9248, Std Dev: 0.0028\n",
      "XGBoost - Mean CV Accuracy: 0.9572, Std Dev: 0.0027\n",
      "\n",
      "Cross-Validating Models for Target: Label\n",
      "Decision Tree - Mean CV Accuracy: 0.7855, Std Dev: 0.0120\n",
      "Random Forest - Mean CV Accuracy: 0.9579, Std Dev: 0.0089\n",
      "XGBoost - Mean CV Accuracy: 0.9495, Std Dev: 0.0247\n",
      "\n",
      "Cross-Validating Models for Target: Sharpness\n",
      "Decision Tree - Mean CV Accuracy: 0.5702, Std Dev: 0.0326\n",
      "Random Forest - Mean CV Accuracy: 0.7077, Std Dev: 0.0428\n",
      "XGBoost - Mean CV Accuracy: 0.7159, Std Dev: 0.0587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validate each model (optional step, not stored in results dictionary)\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(f\"\\nCross-Validating Models for Target: {target.capitalize()}\")\n",
    "    models = get_models(target)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"{model_name} - Mean CV Accuracy: {cv_scores.mean():.4f}, Std Dev: {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance(model, feature_names, target_name):\n",
    "    importances = model.feature_importances_\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot the top 10 important features\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'][:10], importance_df['Importance'][:10], color='skyblue')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Top 10 Feature Importances for {target_name}\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance for Target: Main_activity\n",
      "\n",
      "Decision Tree Feature Importance for Main_activity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Feature Importance for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mplot_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapitalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support feature importances.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[65], line 6\u001b[0m, in \u001b[0;36mplot_feature_importance\u001b[1;34m(model, feature_names, target_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_feature_importance\u001b[39m(model, feature_names, target_name):\n\u001b[0;32m      5\u001b[0m     importances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[1;32m----> 6\u001b[0m     importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportances\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     importance_df \u001b[38;5;241m=\u001b[39m importance_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Plot the top 10 important features\u001b[39;00m\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32md:\\MotionDataAnalysis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Display feature importance plots for tree-based models (Random Forest and XGBoost)\n",
    "for target, models in trained_models.items():\n",
    "    print(f\"\\nFeature Importance for Target: {target.capitalize()}\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Only plot feature importance for models that support it\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            print(f\"\\n{model_name} Feature Importance for {target.capitalize()}\")\n",
    "            plot_feature_importance(model, X_train, target_name=target.capitalize())\n",
    "        else:\n",
    "            print(f\"{model_name} does not support feature importances.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
