{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "sys.path.append('../')  # Go up one directory\n",
    "\n",
    "from src.data_splitting import split_data, get_split_shapes\n",
    "from src.model_training import get_models\n",
    "from src.model_evaluation import print_results, print_result_for_task, summarize_results, plot_confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7956, 135)\n",
      "\n",
      "main_activity splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "label splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "sharpness splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "cleaned_df = pd.read_csv('..\\\\data\\\\final_data\\\\cleaned_train_data.csv')\n",
    "print(f\"Dataset shape: {cleaned_df.shape}\")\n",
    "\n",
    "# Shuffle the data\n",
    "cleaned_df = cleaned_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "splits = split_data(cleaned_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(get_split_shapes(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: Main_activity\n",
      "Original class distribution: {0: np.int64(3350), 1: np.int64(3014)}\n",
      "Resampled class distribution: {1: np.int64(3291), 0: np.int64(3291)}\n",
      "\n",
      "Target: Label\n",
      "Original class distribution: {4: np.int64(3187), 0: np.int64(765), 5: np.int64(733), 2: np.int64(598), 8: np.int64(433), 3: np.int64(290), 1: np.int64(170), 7: np.int64(103), 6: np.int64(85)}\n",
      "Resampled class distribution: {0: np.int64(3187), 3: np.int64(3187), 1: np.int64(3187), 7: np.int64(3187), 2: np.int64(3187), 6: np.int64(3187), 8: np.int64(3187), 4: np.int64(3186), 5: np.int64(3186)}\n",
      "\n",
      "Target: Sharpness\n",
      "Original class distribution: {2: np.int64(2802), 1: np.int64(2481), 0: np.int64(1081)}\n",
      "Resampled class distribution: {0: np.int64(2792), 2: np.int64(2692), 1: np.int64(2684)}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Initialize SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "\n",
    "# Loop through each target variable to apply SMOTE-Tomek\n",
    "balanced_data = {}\n",
    "for target in ['main_activity', 'label', 'sharpness']:  # Adjust based on your target variable names\n",
    "    X_train, X_test, y_train, y_test = splits[target]\n",
    "    X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "    balanced_data[target] = (X_resampled, X_test, y_resampled, y_test)\n",
    "    print(f\"\\nTarget: {target.capitalize()}\")\n",
    "    print(f\"Original class distribution: {dict(pd.Series(y_train).value_counts())}\")\n",
    "    print(f\"Resampled class distribution: {dict(pd.Series(y_resampled).value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete for Main_activity\n",
      "Normalization complete for Label\n",
      "Normalization complete for Sharpness\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = {}\n",
    "\n",
    "# Loop through balanced data and normalize\n",
    "for target, (X_resampled, X_test, y_resampled, y_test) in balanced_data.items():\n",
    "    X_normalized = scaler.fit_transform(X_resampled)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    normalized_data[target] = (X_normalized, X_test_normalized, y_resampled, y_test)\n",
    "    print(f\"Normalization complete for {target.capitalize()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6582, 132)\n"
     ]
    }
   ],
   "source": [
    "print (normalized_data['main_activity'][0].shape)\n",
    "# print (normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train models based on Balanced and Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "Training Models for Target: Main_activity\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n",
      "----------------------------------------\n",
      "\n",
      "Training Models for Target: Label\n",
      "\n",
      "Training Decision Tree...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n",
      "----------------------------------------\n",
      "\n",
      "Training Models for Target: Sharpness\n",
      "\n",
      "Training Decision Tree...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Dictionary to store results for each target\n",
    "results = {}\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"\\nTraining Models for Target: {target.capitalize()}\")\n",
    "\n",
    "    if target == 'main_activity':\n",
    "        models = get_models(task_type='binary')\n",
    "    else:\n",
    "        models = get_models(task_type=\"multiclass\")  \n",
    "\n",
    "    # dict to store results for each model\n",
    "    target_trained_models = {}\n",
    "    target_results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        # Train each model\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        target_trained_models[model_name] = model # Store trained model\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Store all metrics in the results dictionary\n",
    "        target_results[model_name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'report': class_report,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "      \n",
    "    # Store results for the target\n",
    "    results[target] = target_results\n",
    "    trained_models[target] = target_trained_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for main_activity:\n",
      "--------------------------------------------------\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.8386\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       838\n",
      "           1       0.81      0.85      0.83       754\n",
      "\n",
      "    accuracy                           0.84      1592\n",
      "   macro avg       0.84      0.84      0.84      1592\n",
      "weighted avg       0.84      0.84      0.84      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[691 147]\n",
      " [110 644]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9114\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       838\n",
      "           1       0.91      0.90      0.91       754\n",
      "\n",
      "    accuracy                           0.91      1592\n",
      "   macro avg       0.91      0.91      0.91      1592\n",
      "weighted avg       0.91      0.91      0.91      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[775  63]\n",
      " [ 78 676]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.9460\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       838\n",
      "           1       0.94      0.94      0.94       754\n",
      "\n",
      "    accuracy                           0.95      1592\n",
      "   macro avg       0.95      0.95      0.95      1592\n",
      "weighted avg       0.95      0.95      0.95      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[796  42]\n",
      " [ 44 710]]\n",
      "\n",
      "Results for label:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.3354\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41       191\n",
      "           1       0.12      0.23      0.16        43\n",
      "           2       0.32      0.45      0.37       150\n",
      "           3       0.07      0.14      0.09        72\n",
      "           4       0.64      0.38      0.48       797\n",
      "           5       0.17      0.21      0.19       184\n",
      "           6       0.02      0.05      0.03        21\n",
      "           7       0.02      0.04      0.02        26\n",
      "           8       0.14      0.22      0.17       108\n",
      "\n",
      "    accuracy                           0.34      1592\n",
      "   macro avg       0.21      0.24      0.21      1592\n",
      "weighted avg       0.44      0.34      0.37      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 78  14  24  13  33  12   1   2  14]\n",
      " [  5  10   6   7   7   4   0   0   4]\n",
      " [ 20   6  67  11  20  12   3   1  10]\n",
      " [  4   6   7  10  18  14   2   3   8]\n",
      " [ 68  31  78  72 305 105  25  34  79]\n",
      " [ 12   8  14  15  53  38   4  11  29]\n",
      " [  1   1   3   2   5   4   1   1   3]\n",
      " [  1   0   2   2   7   8   2   1   3]\n",
      " [  2   5   7   9  27  24   4   6  24]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6080\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.51      0.63       191\n",
      "           1       0.32      0.60      0.42        43\n",
      "           2       0.73      0.55      0.63       150\n",
      "           3       0.33      0.28      0.30        72\n",
      "           4       0.70      0.77      0.73       797\n",
      "           5       0.42      0.43      0.43       184\n",
      "           6       0.38      0.24      0.29        21\n",
      "           7       0.24      0.31      0.27        26\n",
      "           8       0.36      0.34      0.35       108\n",
      "\n",
      "    accuracy                           0.61      1592\n",
      "   macro avg       0.48      0.45      0.45      1592\n",
      "weighted avg       0.62      0.61      0.61      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 97  24   9   5  45   5   0   1   5]\n",
      " [  0  26   0   2  12   0   0   0   3]\n",
      " [  3  14  83   5  35   8   0   0   2]\n",
      " [  2   4   1  20  32   3   0   2   8]\n",
      " [ 14   5  17  13 613  82   5  11  37]\n",
      " [  1   3   0   5  72  79   2  11  11]\n",
      " [  0   0   0   0  13   2   5   1   0]\n",
      " [  0   0   0   1  15   1   0   8   1]\n",
      " [  1   6   3  10  44   6   1   0  37]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.6149\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.57      0.67       191\n",
      "           1       0.40      0.60      0.48        43\n",
      "           2       0.73      0.63      0.68       150\n",
      "           3       0.32      0.33      0.33        72\n",
      "           4       0.70      0.77      0.73       797\n",
      "           5       0.37      0.33      0.35       184\n",
      "           6       0.40      0.19      0.26        21\n",
      "           7       0.16      0.15      0.16        26\n",
      "           8       0.38      0.43      0.40       108\n",
      "\n",
      "    accuracy                           0.61      1592\n",
      "   macro avg       0.48      0.45      0.45      1592\n",
      "weighted avg       0.62      0.61      0.61      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  15  13   5  38   2   0   0   9]\n",
      " [  0  26   0   4  10   0   0   0   3]\n",
      " [  2  10  95   7  28   4   0   0   4]\n",
      " [  0   6   2  24  26   5   0   2   7]\n",
      " [ 16   5  18  19 610  80   3  11  35]\n",
      " [  2   1   1   6  88  61   2   8  15]\n",
      " [  1   0   0   2   8   5   4   0   1]\n",
      " [  0   0   0   0  19   1   0   4   2]\n",
      " [  2   2   2   8  39   8   1   0  46]]\n",
      "\n",
      "Results for sharpness:\n",
      "--------------------------------------------------\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.4686\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.38      0.33       270\n",
      "           1       0.50      0.50      0.50       621\n",
      "           2       0.54      0.47      0.50       701\n",
      "\n",
      "    accuracy                           0.47      1592\n",
      "   macro avg       0.44      0.45      0.44      1592\n",
      "weighted avg       0.48      0.47      0.47      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103  88  79]\n",
      " [105 313 203]\n",
      " [149 222 330]]\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.5892\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.40      0.41       270\n",
      "           1       0.60      0.60      0.60       621\n",
      "           2       0.64      0.65      0.64       701\n",
      "\n",
      "    accuracy                           0.59      1592\n",
      "   macro avg       0.55      0.55      0.55      1592\n",
      "weighted avg       0.59      0.59      0.59      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  78  83]\n",
      " [ 73 374 174]\n",
      " [ 78 168 455]]\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.5980\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.46      0.43       270\n",
      "           1       0.62      0.63      0.63       621\n",
      "           2       0.68      0.62      0.65       701\n",
      "\n",
      "    accuracy                           0.60      1592\n",
      "   macro avg       0.56      0.57      0.57      1592\n",
      "weighted avg       0.61      0.60      0.60      1592\n",
      "\n",
      "Confusion Matrix:\n",
      "[[125  76  69]\n",
      " [ 88 394 139]\n",
      " [101 167 433]]\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting confusion matrices...\")\n",
    "plot_confusion_matrices(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validating Models for Target: Main_activity\n",
      "Logistic Regression - Mean CV Accuracy: 0.8441, Std Dev: 0.0125\n",
      "Random Forest - Mean CV Accuracy: 0.9137, Std Dev: 0.0100\n",
      "XGBoost - Mean CV Accuracy: 0.9453, Std Dev: 0.0086\n",
      "\n",
      "Cross-Validating Models for Target: Label\n",
      "Decision Tree - Mean CV Accuracy: 0.7771, Std Dev: 0.0125\n",
      "Random Forest - Mean CV Accuracy: 0.9369, Std Dev: 0.0218\n",
      "XGBoost - Mean CV Accuracy: 0.9225, Std Dev: 0.0293\n",
      "\n",
      "Cross-Validating Models for Target: Sharpness\n",
      "Decision Tree - Mean CV Accuracy: 0.5640, Std Dev: 0.0328\n",
      "Random Forest - Mean CV Accuracy: 0.6832, Std Dev: 0.0561\n",
      "XGBoost - Mean CV Accuracy: 0.6804, Std Dev: 0.0659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validate each model\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(f\"\\nCross-Validating Models for Target: {target.capitalize()}\")\n",
    "    \n",
    "    if target == 'main_activity':\n",
    "        models = get_models(task_type='binary')\n",
    "    else:\n",
    "        models = get_models(task_type=\"multiclass\") \n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"{model_name} - Mean CV Accuracy: {cv_scores.mean():.4f}, Std Dev: {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Save Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/main_activity_Logistic Regression_iter2.pkl\n",
      "Model saved to ../models/main_activity_Random Forest_iter2.pkl\n",
      "Model saved to ../models/main_activity_XGBoost_iter2.pkl\n",
      "Model saved to ../models/label_Decision Tree_iter2.pkl\n",
      "Model saved to ../models/label_Random Forest_iter2.pkl\n",
      "Model saved to ../models/label_XGBoost_iter2.pkl\n",
      "Model saved to ../models/sharpness_Decision Tree_iter2.pkl\n",
      "Model saved to ../models/sharpness_Random Forest_iter2.pkl\n",
      "Model saved to ../models/sharpness_XGBoost_iter2.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the trained models to the models folder\n",
    "for target, target_models in trained_models.items():\n",
    "    for model_name, model in target_models.items():\n",
    "        filename = f\"../models/{target}_{model_name}_iter2.pkl\"\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "            print(f\"Model saved to {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
