{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "sys.path.append('../')  # Go up one directory\n",
    "\n",
    "from src.data_splitting import split_data, get_split_shapes\n",
    "from src.model_training import get_models, train_models_for_task\n",
    "from src.model_evaluation import print_results, print_result_for_task, summarize_results, plot_confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7956, 135)\n",
      "\n",
      "main_activity splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "label splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "\n",
      "sharpness splits:\n",
      "X_train shape: (6364, 132)\n",
      "X_test shape: (1592, 132)\n",
      "y_train shape: (6364,)\n",
      "y_test shape: (1592,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "cleaned_df = pd.read_csv('..\\\\data\\\\final_data\\\\cleaned_train_data.csv')\n",
    "print(f\"Dataset shape: {cleaned_df.shape}\")\n",
    "\n",
    "# Shuffle the data\n",
    "cleaned_df = cleaned_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "splits = split_data(cleaned_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(get_split_shapes(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Feature engineering - Magnitude features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude features added\n",
      "Number of magnitude features: 12\n",
      "(7956, 147)\n"
     ]
    }
   ],
   "source": [
    "joints = ['L5', 'L3', 'T12', 'T8', 'Neck', 'Head',\n",
    "          'RightShoulder', 'RightUpperArm', 'RightForearm', 'RightHand',\n",
    "          'LeftShoulder', 'LeftUpperArm', 'LeftForearm', 'LeftHand',\n",
    "          'RightUpperLeg', 'RightLowerLeg', 'RightFoot', 'RightToe',\n",
    "          'LeftUpperLeg', 'LeftLowerLeg', 'LeftFoot', 'LeftToe']\n",
    "\n",
    "for joint in joints:\n",
    "\n",
    "    vel_cols = [f'{joint} x_Vel', f'{joint} y_Vel', f'{joint} z_Vel']\n",
    "    acc_cols = [f'{joint} x_Acc', f'{joint} y_Acc', f'{joint} z_Acc']\n",
    "\n",
    "\n",
    "    if all(col in cleaned_df.columns for col in vel_cols):\n",
    "        cleaned_df[f'{joint}_Vel_Magnitude'] = np.sqrt(\n",
    "            cleaned_df[vel_cols[0]]**2 + \n",
    "            cleaned_df[vel_cols[1]]**2 + \n",
    "            cleaned_df[vel_cols[2]]**2\n",
    "        )\n",
    "    \n",
    "    # Acceleration magnitude\n",
    "    if all(col in cleaned_df.columns for col in acc_cols):\n",
    "        cleaned_df[f'{joint}_Acc_Magnitude'] = np.sqrt(\n",
    "            cleaned_df[acc_cols[0]]**2 + \n",
    "            cleaned_df[acc_cols[1]]**2 + \n",
    "            cleaned_df[acc_cols[2]]**2\n",
    "        )\n",
    "\n",
    "print(\"Magnitude features added\")\n",
    "magnitude_cols = [col for col in cleaned_df.columns if 'Magnitude' in col]\n",
    "print(f\"Number of magnitude features: {len(magnitude_cols)}\")\n",
    "print(cleaned_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature engineering - Roll features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling features added\n",
      "Number of rolling features: 72\n"
     ]
    }
   ],
   "source": [
    "# Define window sizes for rolling calculations\n",
    "window_sizes = [3, 5]\n",
    "\n",
    "# Calculate rolling features for magnitude columns\n",
    "for window in window_sizes:\n",
    "    for col in magnitude_cols:\n",
    "        # Group by label to avoid mixing statistics across different activities\n",
    "        grouped = cleaned_df.groupby('Label')[col]\n",
    "        \n",
    "        # Calculate rolling statistics\n",
    "        cleaned_df[f'{col}_RollingMean_{window}'] = grouped.transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean())\n",
    "        cleaned_df[f'{col}_RollingStd_{window}'] = grouped.transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std())\n",
    "        cleaned_df[f'{col}_RollingMax_{window}'] = grouped.transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).max())\n",
    "\n",
    "print(\"Rolling features added\")\n",
    "rolling_cols = [col for col in cleaned_df.columns if 'Rolling' in col]\n",
    "print(f\"Number of rolling features: {len(rolling_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = split_data(cleaned_df, test_size=0.2, random_state=42)\n",
    "print(get_split_shapes(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Initialize SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "\n",
    "# Loop through each target variable to apply SMOTE-Tomek\n",
    "balanced_data = {}\n",
    "for target in ['main_activity', 'label', 'sharpness']:\n",
    "    X_train, X_test, y_train, y_test = splits[target]\n",
    "    X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "    balanced_data[target] = (X_resampled, X_test, y_resampled, y_test)\n",
    "    print(f\"\\nTarget: {target.capitalize()}\")\n",
    "    print(f\"Original class distribution: {dict(pd.Series(y_train).value_counts())}\")\n",
    "    print(f\"Resampled class distribution: {dict(pd.Series(y_resampled).value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = {}\n",
    "\n",
    "# Loop through balanced data and normalize\n",
    "for target, (X_resampled, X_test, y_resampled, y_test) in balanced_data.items():\n",
    "    X_normalized = scaler.fit_transform(X_resampled)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    normalized_data[target] = (X_normalized, X_test_normalized, y_resampled, y_test)\n",
    "    print(f\"Normalization complete for {target.capitalize()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Dictionary to store results for each target\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(f\"\\nTraining Models for Target: {target.capitalize()}\")\n",
    "    models = get_models(target)  # Get models specific to this target\n",
    "\n",
    "    target_results = {}\n",
    "    for model_name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        target_results[model_name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'report': class_report,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "    \n",
    "    results[target] = target_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for target, (X_train, X_test, y_train, y_test) in normalized_data.items():\n",
    "    print(f\"\\nCross-Validating Models for Target: {target.capitalize()}\")\n",
    "    models = get_models(target)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"{model_name} - Mean CV Accuracy: {cv_scores.mean():.4f}, Std Dev: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save models for each target\n",
    "for target, target_results in results.items():\n",
    "    target_dir = os.path.join('models', target)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    for model_name, model_data in target_results.items():\n",
    "        model_path = os.path.join(target_dir, f\"{model_name.lower().replace(' ', '_')}.joblib\")\n",
    "        joblib.dump(model_data['model'], model_path)\n",
    "        print(f\"Saved {target} - {model_name} to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
